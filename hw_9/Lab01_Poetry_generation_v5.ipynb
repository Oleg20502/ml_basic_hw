{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IcttzSt0wXl"
      },
      "source": [
        "## Домашнее задание №9\n",
        "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
        "\n",
        "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt-qwQCR0wXn"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import string\n",
        "import os\n",
        "from random import sample\n",
        "\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfOZTh1M0wXo",
        "outputId": "97b8dae1-c4cf-4765-b535-1a7be3e8e347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda device is available\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print('{} device is available'.format(device))\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPenWOy01Ooa",
        "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
      },
      "source": [
        "#### 1. Загрузка данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzKPcG3q0wXp",
        "outputId": "663ccb35-3aa6-460f-85fc-24a37df534bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-15 14:21:57--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "onegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-12-15 14:21:58 (8.00 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "id": "zuUBNA14NLtw",
        "outputId": "9089bd0f-7562-44a2-8e09-602502cf2a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "i\n",
            "\n",
            "«мой дядя самых честных правил,\n",
            "когда не в шутку занемог,\n",
            "он уважать себя заставил\n",
            "и лучше выдумать не мог.\n",
            "его пример другим наука;\n",
            "но, боже мой, какая скука\n",
            "с больным сидеть и день и ночь,\n",
            "не отходя ни шагу прочь!\n",
            "какое низкое коварство\n",
            "полуживого забавлять,\n",
            "ему подушки поправлять,\n",
            "печально подносить лекарство,\n",
            "вздыхать и думать про себя:\n",
            "когда же черт возьмет тебя!»\n",
            "\n",
            "\n",
            "\n",
            "ii\n",
            "\n",
            "так думал молодой повеса,\n",
            "летя в пыли на почтовых,\n",
            "всевышней волею зевеса\n",
            "наследник всех своих родных. —\n",
            "друзья людмилы и руслана!\n",
            "с героем моего романа\n",
            "без предисловий, сей же час\n",
            "позвольте познакомить вас:\n",
            "онегин, добрый мой приятель,\n",
            "родился на брегах невы,\n",
            "где, может быть, родились вы\n",
            "или блистали, мой читатель;\n",
            "там некогда гулял и я:\n",
            "но вреден север для меня\n",
            "\n",
            "\n",
            "iii\n",
            "\n",
            "служив отлично-благородно,\n",
            "долгами жил его отец,\n",
            "давал три бала ежегодно\n",
            "и промотался наконец.\n",
            "судьба евгения хранила:\n",
            "сперва madame за ним ходила,\n",
            "потом monsieur ее сменил;\n",
            "ребенок был резов, но мил.\n",
            "monsieur l’abbe€, француз убогой,\n",
            "чтоб не и\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQYpmGfR_gJ8"
      },
      "source": [
        "#### 2. Построение словаря и предобработка текста\n",
        "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1gaPpkK0wXp",
        "outputId": "8777b345-421b-4d69-d5a7-3520eee4736d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "tokens = sorted(set(text.lower())) + ['<sos>']\n",
        "num_tokens = len(tokens)\n",
        "\n",
        "assert num_tokens == 84, \"Check the tokenization process\"\n",
        "\n",
        "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
        "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
        "\n",
        "print(\"Seems fine!\")\n",
        "\n",
        "\n",
        "text_encoded = [token_to_idx[x] for x in text]\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYetYvee0wXq"
      },
      "source": [
        "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
        "\n",
        "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
        "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
        "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
        "\n",
        "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
        "\n",
        "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3lKpdGK0wXq"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "batch_size = 256\n",
        "seq_length = 100\n",
        "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>']\n",
        "\n",
        "def generate_chunk():\n",
        "    global text_encoded, start_column, batch_size, seq_length\n",
        "\n",
        "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
        "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
        "    yield np.hstack((start_column, data))\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOMtpLbe0wXq"
      },
      "source": [
        "Пример батча:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2hp33_60wXr",
        "outputId": "39bc865b-8e08-43af-d8d5-d22f1ba376e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[83, 59, 62, ..., 50, 58, 73],\n",
              "       [83, 55, 53, ..., 46, 50, 62],\n",
              "       [83, 50, 49, ..., 56, 53,  1],\n",
              "       ...,\n",
              "       [83, 49, 58, ..., 59, 48,  2],\n",
              "       [83,  0,  0, ..., 58, 50, 49],\n",
              "       [83, 59, 62, ..., 45, 62,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "next(generate_chunk())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8rraQ5k0wXr"
      },
      "source": [
        "Далее вам предстоит написать код для обучения модели и генерации текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGUzep9i0wXr"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, num_tokens, embed_size, hidden_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = nn.Embedding(num_tokens, embed_size)\n",
        "        self.i2h = nn.Linear(embed_size + hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, num_tokens)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input)\n",
        "        combined = torch.cat([input, hidden], dim=1)\n",
        "        hidden = self.i2h(combined)\n",
        "        hidden = torch.tanh(hidden)\n",
        "        output = self.h2o(hidden)\n",
        "        output = self.logsoftmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_loop(rnn, batch_ix):\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hidden = rnn.init_hidden(batch_size).to(device)\n",
        "    logprobs = []\n",
        "\n",
        "    for inp in batch_ix.transpose(0, 1):\n",
        "        logp, hidden = rnn(inp, hidden)\n",
        "        logprobs.append(logp)\n",
        "\n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "metadata": {
        "id": "kv1KEK4c2cfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size=20\n",
        "hidden_size=128\n",
        "\n",
        "loss_func = nn.NLLLoss()\n",
        "char_rnn = RNN(num_tokens, embed_size, hidden_size).to(device)\n",
        "\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(char_rnn.parameters(), lr=lr)\n",
        "history = []\n",
        "\n",
        "n_epochs = 10000\n",
        "print_every = 100"
      ],
      "metadata": {
        "id": "5ZS5ISbi2cT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(rnn, loss_func, n_epochs):\n",
        "    for i in range(n_epochs):\n",
        "        batch_ix = torch.tensor(next(generate_chunk()), dtype=torch.int64).to(device)\n",
        "\n",
        "        logp_seq = rnn_loop(rnn, batch_ix)\n",
        "\n",
        "        predictions_logp = logp_seq[:, :-1]\n",
        "        target_tokens = batch_ix[:, 1:]\n",
        "\n",
        "        loss = loss_func(\n",
        "            predictions_logp.reshape(-1, num_tokens),\n",
        "            target_tokens.reshape(-1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.data.cpu().numpy())\n",
        "        if (i+1) % print_every == 0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history, label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gfsDQNc190AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(char_rnn, loss_func, n_epochs)"
      ],
      "metadata": {
        "id": "OhMPIPQ8CCaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg4kV83R0wXr"
      },
      "source": [
        "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1XpPkDv0wXs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfE47QTr0wXs"
      },
      "source": [
        "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ak1iPZh0wXs"
      },
      "outputs": [],
      "source": [
        "def generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "\n",
        "    if seed_phrase is not None:\n",
        "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx[token] for token in seed_phrase]\n",
        "    else:\n",
        "        x_sequence = [token_to_idx['<sos>']]\n",
        "\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "\n",
        "    hidden = char_rnn.init_hidden(1).to(device)\n",
        "\n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        _, hidden = char_rnn(x_sequence[:, i], hidden)\n",
        "\n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        output, hidden, = char_rnn(x_sequence[:, -1], hidden)\n",
        "        p_next = torch.exp(output / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "\n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.cpu().data.numpy()[0]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(char_rnn, ' мой дядя самых честных правил', max_length=250, temperature=0.8))"
      ],
      "metadata": {
        "id": "5oaBRxk_K4Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(char_rnn, ' мой дядя самых честных правил', max_length=250, temperature=0.5))"
      ],
      "metadata": {
        "id": "rwYnxko0NfAe",
        "outputId": "53d2f380-1dca-49dd-cecb-fe603b886128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правиляю до глупоком,\n",
            "и в страшно я забово,\n",
            "и сердце нас ничего страстей дом)\n",
            "не вседсе слез воле\n",
            "срод переб часто на полной\n",
            "увяди думал: все на полный\n",
            "и пестательных душою;\n",
            "мне старельной на друга,\n",
            "когда бы восповали мать.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(char_rnn, ' мой дядя самых честных правил', max_length=250, temperature=0.3))"
      ],
      "metadata": {
        "id": "Evatpn9-NkFt",
        "outputId": "7c1c0b25-3ec2-4af8-f99e-97eb0a1cd4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правиляютилскордость,\n",
            "и в то в ольгин оденье,\n",
            "и в души моей даляна,\n",
            "не похот он не полный водой\n",
            "достойный раз рукой,\n",
            "надежды, полно бездор;\n",
            "душа света и в собластвовал\n",
            "страдает свой полемной\n",
            "в окнем обще в нем сердце лет.\n",
            "\n",
            "\n",
            "\n",
            "x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(char_rnn, ' мой дядя самых честных правил', max_length=250, temperature=0.1))"
      ],
      "metadata": {
        "id": "en3MOECuNnob",
        "outputId": "f4645f22-5a43-4fea-ef4e-6f33922c11c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правиляю тебя\n",
            "она под неже твоетства,\n",
            "как девический приводит\n",
            "и в то в ольгин одна в ней страстей страсть\n",
            "ее страстей страстью,\n",
            "не все предальным сердце насладел\n",
            "и в том сердце в темно привета\n",
            "он под ней на своей полон.\n",
            "\n",
            "\n",
            "\n",
            "xxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample(char_rnn, ' мой дядя самых честных правил', max_length=250, temperature=1))"
      ],
      "metadata": {
        "id": "33dqFxUvNrYL",
        "outputId": "a1d87765-5904-4984-bc84-dd99362f2557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правиляенья;\n",
            "да умы безбуждена хначенье;\n",
            "\n",
            "\n",
            "\n",
            "xvii\n",
            "\n",
            "«ну, как усы такор! —\n",
            "будя, к жеркую то ж на страленья,\n",
            "как друг небесных отцемен,\n",
            "благойстал об ней кахляной\n",
            "не обрасим одона\n",
            "все я, тустя торарой\n",
            "онегин с мал благойбокры,\n",
            "он\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpBpaSq40wXs"
      },
      "source": [
        "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0Wu7dly0wXs",
        "outputId": "133f4bae-f0f5-4ab3-91ab-60e677bb92c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правиляюшь годо,\n",
            "своин из другию убил невужает\n",
            "и запели любви домой\n",
            "уерделой, надрась превлелительницке\n",
            "печейно время взоленный,\n",
            "и следе я лево того подруг,\n",
            "такбе смеет обожны, заляла,\n",
            "но обновити читал ваши ли,\n",
            "татьяна рося,\n",
            "не раз рукой, пораким задол\n",
            "приныло на свокло, хояда\n",
            "сквеж певгенить подъемох представить\n",
            "и наконец верила;\n",
            "хоть так уставане велит,\n",
            "как тем очитая друженья,\n",
            "и радонянья сердце славшой,\n",
            "в ней соседу кто мы е.\n",
            "\n",
            "\n",
            "\n",
            "xxxvii\n",
            "\n",
            "его старал задыва:\n",
            "по вас ольг\n"
          ]
        }
      ],
      "source": [
        "print(generate_sample(char_rnn, ' мой дядя самых честных правил', max_length=500, temperature=0.8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbTPxMwO0wXs"
      },
      "source": [
        "### Сдача задания\n",
        "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
        "\n",
        "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6rRNUAv0wXs"
      },
      "outputs": [],
      "source": [
        "seed_phrase = ' мой дядя самых честных правил'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-PC3VEL0wXs"
      },
      "outputs": [],
      "source": [
        "generated_phrases = [\n",
        "    generate_sample(\n",
        "        char_rnn,\n",
        "        ' мой дядя самых честных правил',\n",
        "        max_length=500,\n",
        "        temperature=0.8\n",
        "    ).replace('<sos>', '')\n",
        "    for _ in range(10)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_phrases[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd4D760iVr0r",
        "outputId": "873b971a-331f-40a4-d2f2-e0a39ba555cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " мой дядя самых честных правилена\n",
            "всегда ей всповедит мновом,\n",
            "пустой молодой,\n",
            "на вечер старика ромный,\n",
            "не сплива и кажным слез,\n",
            "и прандох посных из окилей\n",
            "мне счуж не рад небут видит замервый порыва;\n",
            "по толковейшины! бысловой,\n",
            "на вотам сей стала доброй\n",
            "слезы приятку отвычной\n",
            "душа страх иль она с подрух;\n",
            "старишке ж не уж байская тень\n",
            "так на мало венерном\n",
            "пред ниму вечер плакала,\n",
            "хоть на него женточет,\n",
            "любил большя всё трика\n",
            "и забыл по волненья;\n",
            "зарецт одохнакой моей.\n",
            "поэт ей не глядит\n",
            "симана полн\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Wgfu2f0wXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7175ec7e-05bd-40b4-9e64-ce73838976cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "import json\n",
        "if 'generated_phrases' not in locals():\n",
        "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
        "\n",
        "for phrase in generated_phrases:\n",
        "\n",
        "    if not isinstance(phrase, str):\n",
        "        raise ValueError(\"The generated phrase should be a string\")\n",
        "\n",
        "    if len(phrase) != 500:\n",
        "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
        "\n",
        "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
        "\n",
        "\n",
        "submission_dict = {\n",
        "    'token_to_idx': token_to_idx,\n",
        "    'generated_phrases': generated_phrases\n",
        "}\n",
        "\n",
        "with open('submission_dict.json', 'w') as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print('File saved to `submission_dict.json`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyY7C8gc0wXt"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, num_tokens, embed_size, hidden_size):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = nn.Embedding(num_tokens, embed_size)\n",
        "        self.lstm = nn.LSTMCell(embed_size, hidden_size)\n",
        "        self.decoder = nn.Linear(hidden_size, num_tokens)\n",
        "\n",
        "    def forward(self, input, h, c):\n",
        "        input = self.encoder(input)\n",
        "        h, c = self.lstm(input, (h, c))\n",
        "        output = self.decoder(h)\n",
        "        return output, h, c\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
      ],
      "metadata": {
        "id": "jB0rudqRWGPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_loop(rnn, batch_ix):\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    h = rnn.init_hidden(batch_size).to(device)\n",
        "    c = rnn.init_hidden(batch_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    for inp in batch_ix.transpose(0, 1):\n",
        "        output, h, c = rnn(inp, h, c)\n",
        "        outputs.append(output)\n",
        "\n",
        "    return torch.stack(outputs, dim=1)\n",
        "\n",
        "def lstm_train(rnn, loss_func, n_epochs):\n",
        "    for i in range(n_epochs):\n",
        "        batch_ix = torch.tensor(next(generate_chunk()), dtype=torch.int64).to(device)\n",
        "\n",
        "        seq = lstm_loop(rnn, batch_ix)\n",
        "\n",
        "        predictions_seq = seq[:, :-1]\n",
        "        target_tokens = batch_ix[:, 1:]\n",
        "\n",
        "        loss = loss_func(\n",
        "            predictions_seq.reshape(-1, num_tokens),\n",
        "            target_tokens.reshape(-1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.data.cpu().numpy())\n",
        "        if (i+1) % print_every == 0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history, label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gYF76QOc20yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size=20\n",
        "hidden_size=128\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "char_lstm = LSTM(num_tokens, embed_size, hidden_size)\n",
        "char_lstm.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(char_lstm.parameters(), lr=lr)\n",
        "history = []\n",
        "\n",
        "n_epochs = 10000\n",
        "print_every = 100"
      ],
      "metadata": {
        "id": "ea7hfgt0WLLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_train(char_lstm, loss_func, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "4NQrPlESb9OB",
        "outputId": "e7e31ec9-e8ba-4230-e9ff-7d71d29238a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "\n",
        "    if seed_phrase is not None:\n",
        "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx[token] for token in seed_phrase]\n",
        "    else:\n",
        "        x_sequence = [token_to_idx['<sos>']]\n",
        "\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "\n",
        "    h = char_rnn.init_hidden(1).to(device)\n",
        "    c = char_rnn.init_hidden(1).to(device)\n",
        "\n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        _, h, c = char_rnn(x_sequence[:, i], h, c)\n",
        "\n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        output, h, c = char_rnn(x_sequence[:, -1], h, c)\n",
        "        p_next = F.softmax(output / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "\n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.cpu().data.numpy()[0]])"
      ],
      "metadata": {
        "id": "xdk4bREkclbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm_generate_sample(char_lstm, ' мой дядя самых честных правил', max_length=250, temperature=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRBnYYvu8FSV",
        "outputId": "9dd724d1-d4fc-4fad-d02b-26ce6f00fe50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правиладкий):\n",
            "он не извета тихо, ть мой\n",
            "в ее рожды, ручей одет\n",
            "поступливий в дохвя разговы,\n",
            "землала на чести покасны,\n",
            "и заперкою мои толком;\n",
            "всё бессуждены посланих.\n",
            "за чудоваю льбом, как утвой\n",
            "тревог и жар нет об,\n",
            "тестих, как\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm_generate_sample(char_lstm, ' мой дядя самых честных правил', max_length=250, temperature=0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU1ErBeE-yMv",
        "outputId": "b85229ec-a516-4722-d975-f382ff06ff1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правилядеть\n",
            "меж тем дверь нас не постелелья,\n",
            "и в деревню в постеле свойми\n",
            "и забот и первый призвать.\n",
            "\n",
            "\n",
            "\n",
            "xxxvi\n",
            "\n",
            "вставай: все досуждено отворит,\n",
            "и в коро, с толк в грандисона,\n",
            "что нет ольгу ей нет она\n",
            "два столь был подобно в сво\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm_generate_sample(char_lstm, ' мой дядя самых честных правил', max_length=250, temperature=0.000001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjTrnPWJ-6gl",
        "outputId": "f7fb8d89-dea5-45eb-f1e0-7bb90d06e361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> мой дядя самых честных правилядеть,\n",
            "порой разговой подвижальной\n",
            "в сем сердце говорил с тобой.\n",
            "приболвилась полон странный,\n",
            "всегда волиненный потре,\n",
            "сей понять в деревня в уноте,\n",
            "и страшно здесь с покою: ночно\n",
            "всё там ленью шевелась,\n",
            "в глуши в страшн\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LK7vihglBJX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}